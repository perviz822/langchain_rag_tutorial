{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f7bef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "question= \"What is the biggest animal on earth\"\n",
    "\n",
    "document= \"The most huge mammal in the world is elephant \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daaac89",
   "metadata": {},
   "source": [
    "### A function that calculates the token for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7feb5420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3923, 374, 279, 8706, 10065, 389, 9578]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string (string:str,encoding_name:str)->int:\n",
    "    '''Takes a token -> encodes it-> counts the number of tokens'''\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    print(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "tokens = num_tokens_from_string(question,'cl100k_base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10769143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "query_result = model.encode([question])\n",
    "document_result = model.encode([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b83693da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 768)\n",
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(type(query_result))\n",
    "print(type(query_result))\n",
    "\n",
    "print(query_result.shape)\n",
    "print(document_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0f549aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.7984286\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "\n",
    "def cosine_similarity(vect1,vect2):\n",
    "    vect1 = vect1.flatten()  # convert (1, 384) â†’ (384,)\n",
    "    vect2 = vect2.flatten()\n",
    "    dot_product = np.dot(vect1.flatten(),vect2)\n",
    "    norm1 = np.linalg.norm(vect1)\n",
    "    norm2 = np.linalg.norm(vect2)\n",
    "    similarity = dot_product /  (norm1*norm2)\n",
    "    return similarity\n",
    "\n",
    "similarity_score = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38d89a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load document\n",
    "with open('documents.txt',\"r\",encoding=\"utf-8\") as f:\n",
    "    loaded_docs = [line.strip() for  line in f.readlines()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa00cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " elem \"The blue whale is known as the largest animal on Earth, reaching lengths of up to 100 feet and weights of around 200 tons. These marine mammals dominate the oceans in size and are remarkable creatures.\",\n",
      " elem \"Elephants are the largest land animals, with males weighing up to 12,000 pounds and standing 10-13 feet tall at the shoulder. Their massive size, intelligence, and social behavior make them truly impressive.\",\n",
      " elem \"Whales are among the largest living animals in the oceans. The blue whale holds the record for the biggest, surpassing all other creatures, both on land and in the sea, in sheer mass and length.\",\n",
      " elem \"Sharks vary in size, but the whale shark is the biggest fish in the world, reaching lengths of over 60 feet. Despite their enormous size, whale sharks are gentle filter feeders.\",\n",
      " elem \"The largest creatures ever to exist are marine animals, specifically whales. Their immense size allows them to store energy efficiently and navigate vast oceanic distances during migration.\"\n"
     ]
    }
   ],
   "source": [
    "for  elem in loaded_docs:\n",
    "    print(\" elem\",elem)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d71ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoded_documents = np.zeros((5,768))\n",
    "\n",
    "for i,doc in enumerate(loaded_docs):\n",
    "    encoded_documents[i] =model.encode([loaded_docs[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "394a9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7713140596920469\n",
      "0.7027656968877771\n",
      "0.6811890522403985\n",
      "0.5588066512575273\n",
      "0.5971161464954607\n"
     ]
    }
   ],
   "source": [
    "for document in encoded_documents:\n",
    "    print(cosine_similarity(document,query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e251d4",
   "metadata": {},
   "source": [
    "## build a text splitter for pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bda712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"hungary_immigration.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size =1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function= len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea46b60",
   "metadata": {},
   "source": [
    "## Building vectorstore and retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "759d5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(documents= splits,embedding=embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs ={\"k\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258a5c7a",
   "metadata": {},
   "source": [
    "## Building the rag chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014fa0c",
   "metadata": {},
   "source": [
    "### Creating the tamplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define the RAC prompt\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "Use the following context to answer the question accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a175b",
   "metadata": {},
   "source": [
    "### Setting up the  DeepSeek LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2132599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"DEEP_SEEK_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"DEEP_SEEK_API_KEY not found in environment variables\")\n",
    "\n",
    "# Use OpenAI-compatible client directly\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com/v1\",\n",
    "    model=\"deepseek-chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d51ada",
   "metadata": {},
   "source": [
    "### Building the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "210c1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided legal text from Hungary's immigration law, here is what you can learn about family reunification:\n",
      "\n",
      "**Eligible Family Members for Reunification:**\n",
      "A residence permit for the purpose of family coexistence can be issued to:\n",
      "*   The **dependent parent** of a family reunifier, their spouse, or a recognized refugee.\n",
      "*   The **brother and direct relative** of the above, but only if the relative is unable to take care of themselves due to their health condition.\n",
      "\n",
      "**Specific Conditions for Spouses:**\n",
      "*   The **spouse of a recognized refugee** is eligible if the marriage was concluded *before* the refugee entered Hungary.\n",
      "*   The **spouse of a family reunifier** is *not* eligible if the reunifier's *other spouse* already has a residence visa or permit for family coexistence (this clause appears to address polygamous marriages).\n",
      "\n",
      "**Important Procedural Note:**\n",
      "An application for a residence permit for the purpose of family reunification **cannot be refused solely** because a document proving the family relationship is unavailable.\n",
      "\n",
      "**Right to Further Residence:**\n",
      "A family member who has not acquired the right of residence under another legal title is entitled to further residence.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Invoke\n",
    "question = \" I want to learn about family reunification\"\n",
    "result = rag_chain.invoke(question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
